{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f47982-f0bd-44b1-b152-489af6845dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.object = object\n",
    "np.int = int\n",
    "np.float = float\n",
    "np.bool = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab97597-8d48-458d-b010-8c3c34a90835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import re\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f288d95-afee-44f3-8c7e-eabb10e30ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_as_int</th>\n",
       "      <th>answer_as_int</th>\n",
       "      <th>question_len</th>\n",
       "      <th>answer_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>71</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n",
       "      <td>55</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n",
       "      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n",
       "      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n",
       "      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>221608</td>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n",
       "      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>221609</td>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n",
       "      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>221610</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n",
       "      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>221611</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>221612</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           question  \\\n",
       "0                1  Well, I thought we'd start with pronunciation,...   \n",
       "1                2  Not the hacking and gagging and spitting part....   \n",
       "2                3  You're asking me out.  That's so cute. What's ...   \n",
       "3                4  No, no, it's my fault -- we didn't have a prop...   \n",
       "4                9     Gosh, if only we could find Kat a boyfriend...   \n",
       "...            ...                                                ...   \n",
       "139404      221608    Well that one. The one who keeps looking at me.   \n",
       "139405      221609  Choose your targets men. That's right Watch th...   \n",
       "139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407      221611                           Your orders, Mr Vereker?   \n",
       "139408      221612  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \\\n",
       "0       Not the hacking and gagging and spitting part....   \n",
       "1       Okay... then how 'bout we try out some French ...   \n",
       "2                                              Forget it.   \n",
       "3                                                Cameron.   \n",
       "4                               Let me see what I can do.   \n",
       "...                                                   ...   \n",
       "139404  ft could be you flatter yourself CoghilL It's ...   \n",
       "139405  Keep steady. You're the best shots of the Twen...   \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n",
       "139407  I'm to take the Sikali with the main column to...   \n",
       "139408  Lord Chelmsford seems to want me to stay back ...   \n",
       "\n",
       "                                          question_as_int  \\\n",
       "0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n",
       "1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n",
       "2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n",
       "3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n",
       "4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n",
       "...                                                   ...   \n",
       "139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n",
       "139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n",
       "139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n",
       "139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n",
       "139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n",
       "\n",
       "                                            answer_as_int  question_len  \\\n",
       "0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n",
       "1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n",
       "2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n",
       "3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n",
       "4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n",
       "...                                                   ...           ...   \n",
       "139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n",
       "139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n",
       "139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n",
       "139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n",
       "139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n",
       "\n",
       "        answer_len  \n",
       "0               55  \n",
       "1               73  \n",
       "2               10  \n",
       "3                8  \n",
       "4               25  \n",
       "...            ...  \n",
       "139404          59  \n",
       "139405          85  \n",
       "139406          60  \n",
       "139407          56  \n",
       "139408          62  \n",
       "\n",
       "[139409 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('D:\\dialogs_expanded.csv\\dialogs_expanded.csv', index_col=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24a8758-7eed-4de9-a304-c7980d8ad7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d0b9cd-bcea-4c2a-ba9f-91f31e25d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139409 entries, 0 to 139408\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   question  139409 non-null  object\n",
      " 1   answer    139409 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671bac95-1622-4f03-a7d8-55be2d778946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       Well, I thought we'd start with pronunciation,...   \n",
       "1       Not the hacking and gagging and spitting part....   \n",
       "2       You're asking me out.  That's so cute. What's ...   \n",
       "3       No, no, it's my fault -- we didn't have a prop...   \n",
       "4          Gosh, if only we could find Kat a boyfriend...   \n",
       "...                                                   ...   \n",
       "139404    Well that one. The one who keeps looking at me.   \n",
       "139405  Choose your targets men. That's right Watch th...   \n",
       "139406  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407                           Your orders, Mr Vereker?   \n",
       "139408  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \n",
       "0       Not the hacking and gagging and spitting part....  \n",
       "1       Okay... then how 'bout we try out some French ...  \n",
       "2                                              Forget it.  \n",
       "3                                                Cameron.  \n",
       "4                               Let me see what I can do.  \n",
       "...                                                   ...  \n",
       "139404  ft could be you flatter yourself CoghilL It's ...  \n",
       "139405  Keep steady. You're the best shots of the Twen...  \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n",
       "139407  I'm to take the Sikali with the main column to...  \n",
       "139408  Lord Chelmsford seems to want me to stay back ...  \n",
       "\n",
       "[139409 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e70e13-add1-4625-807a-aca2f88ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): #---------- defult cleaning function to use any time ...\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]',' ',text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\.S+',' ',text)\n",
    "    text = re.sub('<.*?>+',' ',text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    text = re.sub('[^\\w]',' ',text)\n",
    "    text = re.sub('\\w*\\d\\w*',' ',text)\n",
    "    return text\n",
    "\n",
    "data_df.question = data_df.question.map(clean_text)\n",
    "data_df.answer = data_df.answer.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de4ea64-c179-4423-a357-da2cfec4ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end(text):\n",
    "    text = f'<start> {text} <end>'\n",
    "    return text\n",
    "\n",
    "data_df.question = data_df.question.map(add_start_end)\n",
    "data_df.answer = data_df.answer.map(add_start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8726d-b6dd-4918-bbc1-f3cc6ab1dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; well  i thought we d start with pronun...</td>\n",
       "      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n",
       "      <td>&lt;start&gt; okay    then how  bout we try out some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; you re asking me out   that s so cute ...</td>\n",
       "      <td>&lt;start&gt; forget it  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; no  no  it s my fault    we didn t hav...</td>\n",
       "      <td>&lt;start&gt; cameron  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; gosh  if only we could find kat a boyf...</td>\n",
       "      <td>&lt;start&gt; let me see what i can do  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>&lt;start&gt; well that one  the one who keeps looki...</td>\n",
       "      <td>&lt;start&gt; ft could be you flatter yourself coghi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>&lt;start&gt; choose your targets men  that s right ...</td>\n",
       "      <td>&lt;start&gt; keep steady  you re the best shots of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>&lt;start&gt; colonel durnford    william vereker  i...</td>\n",
       "      <td>&lt;start&gt; good ones  yes  mr vereker  gentlemen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>&lt;start&gt; your orders  mr vereker  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n",
       "      <td>&lt;start&gt; lord chelmsford seems to want me to st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       <start> well  i thought we d start with pronun...   \n",
       "1       <start> not the hacking and gagging and spitti...   \n",
       "2       <start> you re asking me out   that s so cute ...   \n",
       "3       <start> no  no  it s my fault    we didn t hav...   \n",
       "4       <start> gosh  if only we could find kat a boyf...   \n",
       "...                                                   ...   \n",
       "139404  <start> well that one  the one who keeps looki...   \n",
       "139405  <start> choose your targets men  that s right ...   \n",
       "139406  <start> colonel durnford    william vereker  i...   \n",
       "139407             <start> your orders  mr vereker  <end>   \n",
       "139408  <start> i m to take the sikali with the main c...   \n",
       "\n",
       "                                                   answer  \n",
       "0       <start> not the hacking and gagging and spitti...  \n",
       "1       <start> okay    then how  bout we try out some...  \n",
       "2                                <start> forget it  <end>  \n",
       "3                                  <start> cameron  <end>  \n",
       "4                 <start> let me see what i can do  <end>  \n",
       "...                                                   ...  \n",
       "139404  <start> ft could be you flatter yourself coghi...  \n",
       "139405  <start> keep steady  you re the best shots of ...  \n",
       "139406  <start> good ones  yes  mr vereker  gentlemen ...  \n",
       "139407  <start> i m to take the sikali with the main c...  \n",
       "139408  <start> lord chelmsford seems to want me to st...  \n",
       "\n",
       "[139409 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a838cd2-ce87-489b-b5b9-df5295336728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters='!\"#$%&()*+,-./:;=?@[\\]^_`{|}~\\t\\n', oov_token='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4b52c5-2d96-4faf-8354-fbb0d3eb21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_sequence, question_tokenizer = tokenize(data_df.question)\n",
    "answer_sequence, answer_tokenizer = tokenize(data_df.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a813625b-188c-4828-b1a2-c4e3a6c9697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125468, 29), (13941, 29), (125468, 32), (13941, 32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(question_sequence, \n",
    "                answer_sequence, test_size = 0.1, random_state=42) \n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4021401e-225e-4854-a8cb-932775a0f90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "2---> <start>\n",
      "80---> yeah\n",
      "13---> that\n",
      "8---> s\n",
      "11004---> blush\n",
      "36---> on\n",
      "32---> my\n",
      "301---> wife\n",
      "3384---> uses\n",
      "9---> it\n",
      "3---> <end>\n",
      "\n",
      "Answer\n",
      "2---> <start>\n",
      "204---> ask\n",
      "5535---> travis\n",
      "22---> he\n",
      "7---> s\n",
      "6---> the\n",
      "1765---> ladies\n",
      "104---> man\n",
      "3---> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print('%d---> %s' % (t, lang.index_word[t]))\n",
    "\n",
    "print('Question')\n",
    "convert(question_tokenizer, x_train[0])\n",
    "print()\n",
    "print('Answer')\n",
    "convert(answer_tokenizer, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734e069f-551d-48fa-9068-21cc2a47eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inp_size = len(question_tokenizer.word_index)+1\n",
    "vocab_tar_size =  len(answer_tokenizer.word_index)+1\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e913becf-5c8a-4ae7-9079-c9639e01c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x, y, batch_size=32):\n",
    "    \n",
    "    data = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    data = data.shuffle(1028)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_dataset = create_dataset(x_train, y_train)\n",
    "test_dataset = create_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b054f4-a081-4752-b5eb-6cbc0ca5de5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:(32, 29)\n",
      "[[    2    12    29     4   111    44    19     6  3578  1043  3003     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    17    28    10   203 20265     5    23   415   131     3     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    39    86  7134     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5   308     9     9     8    39    31    47     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    29    43   146    53    47     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    67   145     9    35   150   131   143   106   148   317    22\n",
      "    237    14    88    42    92  1429     3     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    45   130    32  2439     4    25  1114     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  1054  1213     5    23   449     4  5663     5    35    66   484\n",
      "     55   238    53    17    25    64     7    37   861     3     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    12   123     5   238    69     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     4    25    68    16   102   273    11     4    10   249  2283\n",
      "      3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    24   163    11    32   232   206     9     8    39    10  6507\n",
      "      3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    18    47   149    83 14586    89     6   882  5198   125    43\n",
      "     29  1010     3     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   268     5    23   643 16488    89     6  4843     5    23    44\n",
      "      7   522    60   373  3052     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   183    47    15    13   184   857     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    12    35     9    27     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    12    29    43     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   133  1535    12    15    13    54  2311   121     9    60     5\n",
      "     63   104   257    13    36 11631     3     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  5911     8  3104     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    48    38   150    96     4    37    19  1995     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   581    17    37    50    66     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    28     4   157   826    42    24    40   354   221     3     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    13     8   256   555   219    11     9   493     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    98     6 12997  6702  5284   733     5  5335     6   112   172\n",
      "   1698    29   247   730    19     6  4533     3     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     4    26    50    13    58   172  3191    95   129   319    20\n",
      "      4   170     9    13    10   196   149    10  1181     3     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  1504    20     4    28   119   283    12     6  2349    29   603\n",
      "   2350     6  8087     3     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  1686    18  1696   299  4370  3065   669  1476  2547  4784     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5    23    64    36  2067    69     6   691     8  1165     7\n",
      "    152    27 14941     3     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    72     8    57    55     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    10   232  9825     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    38    76   335    90     8     4   152    44     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    48    12     3     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    62     5    21    11     5    93     5    95   103    17    95\n",
      "     39   129     3     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n",
      "Answer:(32, 32)\n",
      "[[  2 114   4 ...   0   0   0]\n",
      " [  2  19  17 ...   0   0   0]\n",
      " [  2 122   7 ...   0   0   0]\n",
      " ...\n",
      " [  2 402  16 ...   0   0   0]\n",
      " [  2   4  17 ...   0   0   0]\n",
      " [  2  23   5 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "for q, a in train_dataset.take(1):\n",
    "    print(f'Question:{q.shape}\\n{q}')\n",
    "  \n",
    "    print(f'Answer:{a.shape}\\n{a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9989caa-08da-4aac-b8a8-bf03b8bb0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.gru = tf.keras.layers.GRU(self.encoder_units, \n",
    "                                           return_sequences=True,\n",
    "                                           return_state=True,\n",
    "                                           recurrent_initializer = 'glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "491b4bab-9e4a-4eb7-86a9-22005a55571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.gru = tf.keras.layers.GRU(self.decoder_units, \n",
    "                                           return_sequences=True,\n",
    "                                           return_state=True,\n",
    "                                           recurrent_initializer = 'glorot_uniform')\n",
    "      \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.gru(x, initial_state = hidden)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x =  tf.nn.softmax(self.fc(output))\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9b8083-f923-4a1a-af70-a01aac4fc328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (32, 29, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (32, 1024)\n"
     ]
    }
   ],
   "source": [
    "# vocab_inp_size = len(eng_tokenizer.word_index)+1\n",
    "# vocab_tar_size =  len(spn_tokenizer.word_index)+1\n",
    "# embedding_dim = 256\n",
    "# units = 1024\n",
    "# batch_size=32\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(q, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "310e16cb-deda-4b20-bfa5-d73b0c72d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch size, vocab_size) (32, 27850)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n",
    "\n",
    "sample_decoder_output, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden)\n",
    "\n",
    "print ('Decoder output shape: (batch size, vocab_size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c50a79-7a82-464e-a554-825a368d4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the optimizer using the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# create the loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')\n",
    "\n",
    "# define the loss function for the training\n",
    "def loss_function(real, pred):\n",
    "    # create the mask to ignore the padding tokens\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    # mask shape == (batch_size, sequence_length)\n",
    "    # calculate the loss\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # mask the loss\n",
    "    # how the mask works:\n",
    "    # if the value is 1, the loss is calculated\n",
    "    # if the value is 0, the loss is ignored\n",
    "      #[1,1,1,1,1,1,0,0,0,0,0] mask\n",
    "      # *\n",
    "      #[2,6,2,1,6,3,2,1,5,7,9] input\n",
    "      # =\n",
    "      #[2,6,2,1,6,3,0,0,0,0,0] output\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # mask shape == (batch_size, sequence_length)\n",
    "\n",
    "    loss_ *= mask\n",
    "    # calculate the average loss per batch \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d73760-db55-4aec-b708-c38a11cc86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training metric \n",
    "train_loss = tf.metrics.Mean(name='train loss')\n",
    "# create the testing metric \n",
    "test_loss =tf.metrics.Mean(name='test loss')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15267b46-848d-4505-a964-9745b462fe6d",
   "metadata": {},
   "source": [
    "# create the training step\n",
    "# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n",
    "@tf.function\n",
    "# define the training step \n",
    "def train_step(inputs, target, enc_hidden):\n",
    "    # the encoder_hidden is the initial hidden state of the encoder\n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "\n",
    "    # inilaize the loss to zero\n",
    "    loss = 0\n",
    "  # create the gradient tape to record the gradient of the loss with respect to the weights\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # pass the input to the encoder\n",
    "        # enc_output shape == (batch_size, 49, hidden_size)\n",
    "        # enc_hidden shape == (batch_size, hidden_size)\n",
    "        # using the encoder to get the encoder_output and the encoder_hidden\n",
    "        # using the encoder_hidden as the initial hidden state of the decoder\n",
    "        enc_output, enc_hidden = encoder(inputs, enc_hidden)\n",
    "        # set the initial decoder hidden state to the encoder hidden state\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "    # create the start token \n",
    "    # start_token shape == (batch_size, 1)\n",
    "    # repeat the start token for the batch size times\n",
    "    dec_input = tf.expand_dims([answer_tokenizer.word_index['']] * inputs.shape[0], 1)\n",
    "    \n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    \n",
    "    for t in range(1, target.shape[1]):\n",
    "        # passing enc_output to the decoder\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "        # calculate the loss for the current time step using the loss function\n",
    "        loss += loss_function(target[:, t], predictions)\n",
    "\n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(target[:, t], 1)\n",
    "    # calculate the loss for the current batch\n",
    "    batch_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "  # get the trainable variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  # calculate the gradients using the tape \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "  # update the trainable variables\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    # add the loss to the training loss metric\n",
    "    train_loss(batch_loss)\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "925afd05-f661-4198-be93-d32706ca186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, target, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inputs, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([answer_tokenizer.word_index['']] * inputs.shape[0], 1)\n",
    "\n",
    "        for t in range(1, target.shape[1]):\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "            loss += loss_function(target[:, t], predictions)\n",
    "\n",
    "            dec_input = tf.expand_dims(target[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(batch_loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    train_loss(batch_loss)\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5fc588e-b751-4807-b5e0-af172d97d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training step\n",
    "# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n",
    "@tf.function \n",
    "def test_step(inputs, target, enc_hidden):\n",
    "    # the encoder_hidden is the initial hidden state of the encoder\n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "    # inilaize the loss to zero\n",
    "    loss = 0\n",
    "    # pass the input to the encoder \n",
    "    # enc_output shape == (batch_size, 49, hidden_size) \n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "    # using the encoder to get the encoder_output and the encoder_hidden\n",
    "    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n",
    "    # set the initial decoder hidden state to the encoder hidden state\n",
    "    dec_hidden = enc_hidden\n",
    "    # create the start token\n",
    "    # start_token shape == (batch_size, 1)\n",
    "    # repeat the start token for the batch size times\n",
    "    dec_input = tf.expand_dims([answer_tokenizer.word_index['']] * inputs.shape[0], 1)\n",
    "    for t in range(1, target.shape[1]):\n",
    "        # passing enc_output to the decoder with dec_hidden as the initial hidden state\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "        # calculate the loss for the current time step using the loss function \n",
    "        loss += loss_function(target[:, t], predictions)\n",
    "\n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(target[:, t], 1)\n",
    "    # calculate the loss for the current batch\n",
    "    batch_loss = (loss / int(target.shape[1]))\n",
    "    # add the batch loss to the test loss metric\n",
    "    test_loss(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "920832e0-7451-4ab6-baa2-d82243d07330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4355/4356 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/models/encoder\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/models/encoder\\assets\n",
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/models/decoder\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/models/decoder\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved\n",
      "##################################################\n",
      "Epoch #1\n",
      "Training Loss 1.3988901376724243\n",
      "Testing Loss 1.2896350622177124\n",
      "##################################################\n",
      " 209/4356 [>.............................] - ETA: 18:21"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# run the training step\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     bar\u001b[38;5;241m.\u001b[39mupdate(count)  \u001b[38;5;66;03m# manually update the progress bar\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# iterate over the testing dataset    \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# set the epochs to 10\n",
    "EPOCHS = 10\n",
    "# set the old test loss to high number \n",
    "\n",
    "old_test_loss=1000000\n",
    "# create the training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset the training loss metric\n",
    "    train_loss.reset_states()\n",
    "    # reset the testing loss metric\n",
    "    test_loss.reset_states()\n",
    "\n",
    "    # initalize the hidden state of the encoder to zeros \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    # create the training progress bar set the total number of batches to the length of the training dataset and the batch size to the test size\n",
    "    steps_per_epoch = answer_sequence.shape[0]//batch_size #=> 4356 batch in the dataset \n",
    "    bar = tf.keras.utils.Progbar(target=steps_per_epoch)\n",
    "    \n",
    "    count=0\n",
    "    # iterate over the training dataset \n",
    "    for (batch, (inputs, target)) in enumerate(train_dataset):\n",
    "        # update the progress bar\n",
    "        count += 1\n",
    "        # run the training step\n",
    "        batch_loss = train_step(inputs, target, enc_hidden)\n",
    "        bar.update(count)  # manually update the progress bar\n",
    "                                                  \n",
    "    \n",
    "         \n",
    "    \n",
    "    # iterate over the testing dataset    \n",
    "    for (batch, (inputs, target)) in enumerate(test_dataset):\n",
    "        count += 1\n",
    "        # run the testing step\n",
    "        batch_loss = test_step(inputs, target, enc_hidden)\n",
    "        bar.update(count)\n",
    "    # save the best performance model on the test dataset \n",
    "    \n",
    "    if old_test_loss> test_loss.result():\n",
    "        # set the old test loss to the test loss \n",
    "        old_test_loss= test_loss.result()\n",
    "        encoder.save(filepath='/content/models/encoder')\n",
    "        decoder.save(filepath='/content/models/decoder')\n",
    "        print('Model is saved')\n",
    "    # print the training and testing loss\n",
    "    print('#' * 50)\n",
    "    print(f'Epoch #{epoch + 1}')\n",
    "    print(f'Training Loss {train_loss.result()}')\n",
    "    print(f'Testing Loss {test_loss.result()}')\n",
    "    print('#' * 50)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2184a5bd-e258-4648-a451-b2e1696ce818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chatbot function\n",
    "# the chatbot function takes in the question as input and answers the input sentence \n",
    "def chatbot(sentence):\n",
    "  \n",
    "  # clean the input question sentence \n",
    "  sentence = clean_text(sentence)\n",
    "  # add the start token to the sentence\n",
    "  sentence =add_start_end(sentence)\n",
    "  # tokenize the sentence\n",
    "  inputs = question_tokenizer.texts_to_sequences([sentence])\n",
    "  # pad the sentence\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                         maxlen=29,\n",
    "                                                         padding='post')\n",
    "  \n",
    "  # initalize the hidden state of the encoder to zeros\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  # pass the sentence to the encoder with the hidden state as the initial hidden state\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "  # set the initial decoder hidden state to the encoder hidden state\n",
    "  dec_hidden = enc_hidden\n",
    "  # create the start token\n",
    "  # start_token shape == (batch_size, 1)\n",
    "  # repeat the start token for the batch size times\n",
    "  dec_input = tf.expand_dims([answer_tokenizer.word_index['']], 0)\n",
    "  # create the result string\n",
    "  result = ''\n",
    "  # loop over the length of the sentence (32)\n",
    "\n",
    "  for t in range(32):\n",
    "    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n",
    "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # getting the predicted word index\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    # getting the predicted word using the predicted index\n",
    "    # add the predicted word to the result string \n",
    "    result += answer_tokenizer.index_word[predicted_id] + ' '\n",
    "    # if the predicted word is the  token then stop the loop\n",
    "    if answer_tokenizer.index_word[predicted_id] == '':\n",
    "      # remove the  and  tokens from the result string\n",
    "      result = result.replace(' ', '')\n",
    "      result = result.replace('  ','')\n",
    "      # remove the  and  tokens from the sentence string\n",
    "      sentence = sentence.replace(' ', '')\n",
    "      sentence = sentence.replace(' ', '')\n",
    "      return  sentence, result\n",
    "\n",
    "    # using the predicted word as the next decoder input\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  # remove the  and  tokens from the result string\n",
    "  result = result.replace(' ', '')\n",
    "  result = result.replace('','')\n",
    "  # remove the  and  tokens from the sentence string\n",
    "  sentence = sentence.replace(' ', '')\n",
    "  sentence = sentence.replace('', '')\n",
    "  \n",
    "\n",
    "  \n",
    " \n",
    "  \n",
    "  # return the result string and the original sentence\n",
    "  return sentence, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "373fb476-2c5c-4dae-8b97-1d49e2a88a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start>canyourun<end>',\n",
       " 'imnotsureimnotsure<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot(\"can you run ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ffe9178-3fdf-48e9-b910-80ff6ab99aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start>whatistheweatheroutside<end>',\n",
       " 'imnotsure<end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end><end>')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('what is the weather outside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e2797-d642-4d1c-a914-631f2bbd5506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
